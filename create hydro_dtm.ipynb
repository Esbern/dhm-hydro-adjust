{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044395d5-95c0-494e-acf4-72f5d2c4217e",
   "metadata": {},
   "source": [
    "The following notebook takes all files in the /data folder and added them to a virtual raster named dtm.vrt it then extracts the boundery of this vrt and form the correction shape file it extracts all correction data that are within this boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78aecb86-c026-4e92-be39-358c435378db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr, osr\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "gdal.UseExceptions()\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325bfbfa-3cb1-4e25-a040-f0239b0c98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_root = Path('D:/GeoILUN/data/Lemvig')\n",
    "corection_root = Path('D:/DK/tilpasninger')\n",
    "src_root = Path('C:/Users/holmes/dev/semanticGIS/projects/GeoILUM/Processes/Hydro_ajust')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacd5a55-48ff-4693-b05c-f7e823afd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rast = dtm_root / 'dtm_10.tif'\n",
    "horseshoe_file = corection_root / 'DHMHestesko.gpkg'\n",
    "hs_filter = dtm_root / 'hs_filter.shp'\n",
    "hs_with_z = dtm_root / 'hs_z.gpkg'\n",
    "line_file = corection_root / 'DHMLinje.gpkg'\n",
    "line_filter = dtm_root / 'line_filter.shp'\n",
    "lines_with_z = dtm_root / 'line_z.gpkg'\n",
    "burn_data = dtm_root / 'burn_z.gpkg'\n",
    "hydro_dtm = dtm_root / 'hydro_dtm.tif'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61301d61-47fc-40e5-80b2-115d4e9ff6c4",
   "metadata": {},
   "source": [
    "## Buildes the Virtual raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b1574-2751-4329-a553-8466930cc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalbuildvrt {data_root}/dtm.vrt {data_root}/*.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44281e-1180-4509-8a88-7e68e0281f5d",
   "metadata": {},
   "source": [
    "## Extract the boundery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9c012d-cea7-4fc0-895c-6153ba3a14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdalSrc = gdal.Open(v_rast)\n",
    "upx, xres, xskew, upy, yskew, yres = gdalSrc.GetGeoTransform()\n",
    "cols = gdalSrc.RasterXSize\n",
    "rows = gdalSrc.RasterYSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2ef7527-882f-4626-b429-fbc09e5fe80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounderybox North Max: 444506 , East min : 6289494\n",
      "Resolution X: 10.000000, Y: -10.000000\n",
      "Size X: 4899, Y: 3499\n",
      "Skew X: 0.000000, Y:0.000000\n",
      "Boundery box:  POLYGON((444506.0 6289494.0,479496.0 6289494.0, 479496.0 6240504.0, 444506.0 6240504.0, 444506.0 6289494.0))\n"
     ]
    }
   ],
   "source": [
    "print(\"Bounderybox North Max: %d , East min : %d\" % (upx,upy))\n",
    "print(\"Resolution X: %f, Y: %f\" %(xres, yres))\n",
    "print(\"Size X: %d, Y: %d\" %(rows, cols))\n",
    "print(\"Skew X: %f, Y:%f\" %(xskew,yskew))\n",
    "\n",
    "#Calculate alle four corners\n",
    "ulx = upx + 0*xres + 0*xskew\n",
    "uly = upy + 0*yskew + 0*yres\n",
    " \n",
    "llx = upx + 0*xres + rows*xskew\n",
    "lly = upy + 0*yskew + rows*yres\n",
    " \n",
    "lrx = upx + cols*xres + rows*xskew\n",
    "lry = upy + cols*yskew + rows*yres\n",
    " \n",
    "urx = upx + cols*xres + 0*xskew\n",
    "ury = upy + cols*yskew + 0*yres\n",
    "\n",
    "# Create WKT for the bounding box\n",
    "bbox_wkt = f\"POLYGON(({ulx} {uly},{urx} {ury}, {lrx} {lry}, {llx} {lly}, {ulx} {uly}))\"\n",
    "bbox_geom = box(ulx, lly, urx, uly)\n",
    "print(\"Boundery box: \", bbox_wkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60d7cb-cae8-4a59-8ea6-442b1bc55895",
   "metadata": {},
   "source": [
    "# Extract horseshoe shooe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e06a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading geometries from 'DHMHestesko.gpkg' intersecting the bounding box...\n",
      "Found 572 intersecting features. Writing to 'hs_filter.shp'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holmes\\AppData\\Local\\Temp\\ipykernel_24188\\602400767.py:31: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(hs_filter, driver='ESRI Shapefile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created shapefile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'datafordeleropdateringstid' to 'datafordel'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'id_namespace' to 'id_namespa'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'geometristatus' to 'geometrist'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'registreringsspecifikation' to 'registreri'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'forretningshaendelse' to 'forretning'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'forretningsomraade' to 'forretni_1'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'forretningsproces' to 'forretni_2'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'registreringsaktoer' to 'registre_1'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'registreringfra' to 'registre_2'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'registreringtil' to 'registre_3'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'virkningsaktoer' to 'virkningsa'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'virkningfra' to 'virkningfr'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'virkningtil' to 'virkningti'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'plannoejagtighed' to 'plannoejag'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'planstedfaestelsesmetode' to 'planstedfa'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'vertikalnoejagtighed' to 'vertikalno'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'vertikalstedfaestelsesmetode' to 'vertikalst'\n",
      "  ogr_write(\n",
      "c:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'applikation' to 'applikatio'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "layer_name = 'dhmhestesko'\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # 1. Create a bounding box geometry from your coordinates\n",
    "\n",
    "    # 2. Read the specific layer from the GeoPackage into a GeoDataFrame\n",
    "    # Geopandas automatically detects the geometry column.\n",
    "    # We can use the 'bbox' parameter for an initial coarse filtering at the read stage.\n",
    "    # This is highly efficient as it uses the spatial index of the GeoPackage.\n",
    "    print(f\"Reading geometries from '{horseshoe_file.name}' intersecting the bounding box...\")\n",
    "    gdf = gpd.read_file(\n",
    "        horseshoe_file,\n",
    "        layer=layer_name,\n",
    "        bbox=bbox_geom\n",
    "    )\n",
    "\n",
    "    # 3. Check if any features were found\n",
    "    if gdf.empty:\n",
    "        print(\"No features found within the specified bounding box. No output file will be created.\")\n",
    "    else:\n",
    "        # 4. Save the filtered GeoDataFrame to a Shapefile\n",
    "        # The CRS is automatically carried over from the source GeoDataFrame.\n",
    "        print(f\"Found {len(gdf)} intersecting features. Writing to '{hs_filter.name}'...\")\n",
    "        gdf.to_file(hs_filter, driver='ESRI Shapefile')\n",
    "        print(\"Successfully created shapefile.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ee6c6-1dc4-4752-8a05-8a9e027da058",
   "metadata": {},
   "source": [
    "# Extract line data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c493c0-2fd1-44cf-9f82-1e229cb15f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ogr2ogr', '-f', 'ESRI Shapefile', WindowsPath('D:/GeoILUN/data/Lemvig/line_filter.shp'), WindowsPath('D:/DK/tilpasninger/DHMLinje.gpkg'), '-dialect', 'SQLITE', '-sql', \"SELECT * FROM 'DHMLinje' WHERE ST_Contains(ST_GeomFromText('POLYGON((444506.0 6289494.0,479496.0 6289494.0, 479496.0 6240504.0, 444506.0 6240504.0, 444506.0 6289494.0))'), geom)\"], returncode=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_column = 'geom'\n",
    "layer_name = 'dhmlinje'\n",
    "\n",
    "base_name = os.path.splitext(os.path.basename(line_file))[0]\n",
    "# SQL query using ST_Contains\n",
    "sql_query = f\"SELECT * FROM '{base_name}' WHERE ST_Contains(ST_GeomFromText('{bbox_wkt}'), geom)\"\n",
    "\n",
    "# Construct the ogr2ogr command\n",
    "cmd = [\n",
    "    'ogr2ogr',\n",
    "    '-f', 'ESRI Shapefile',\n",
    "    line_filter,\n",
    "    line_file,\n",
    "    '-dialect', 'SQLITE',\n",
    "    '-sql', sql_query\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc106669-3eff-45a9-9fb2-0a7a4aac911b",
   "metadata": {},
   "source": [
    "## Use the original Python scripts to first generate the data to be burned and then burn the data into the DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8faba0-77c4-4310-bb43-8586bc240e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', WindowsPath('C:/Users/holmes/dev/semanticGIS/projects/GeoILUM/Processes/Hydro_ajust/cli/sample_line_z.py'), WindowsPath('D:/GeoILUN/data/Lemvig/dtm_10.tif'), WindowsPath('D:/GeoILUN/data/Lemvig/line_filter.shp'), WindowsPath('D:/GeoILUN/data/Lemvig/line_z.gpkg')], returncode=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the original scripts\n",
    "script_path = src_root / 'cli' / 'sample_line_z.py'\n",
    "\n",
    "# Construct the command\n",
    "command = ['python', script_path, v_rast, line_filter, lines_with_z]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acf2f64-2d25-4194-a562-c1138f2a6852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', WindowsPath('C:/Users/holmes/dev/semanticGIS/projects/GeoILUM/Processes/Hydro_ajust/cli/sample_horseshoe_z_lines.py'), WindowsPath('D:/GeoILUN/data/Lemvig/dtm_10.tif'), WindowsPath('D:/GeoILUN/data/Lemvig/hs_filter.shp'), WindowsPath('D:/GeoILUN/data/Lemvig/hs_z.gpkg')], returncode=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the original scripts\n",
    "script_path = src_root / 'cli' / 'sample_horseshoe_z_lines.py'\n",
    "\n",
    "# Construct the command\n",
    "command = ['python', script_path, v_rast, hs_filter, hs_with_z]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250b0ef2-a7f1-47aa-9997-e1b42ff5e470",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "D:\\GeoILUN\\data\\Lemvig\\line_z.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m input_files = [lines_with_z, hs_with_z]\n\u001b[32m     33\u001b[39m output_file = burn_data\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmerge_geopackages\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmerge_geopackages\u001b[39m\u001b[34m(output_gpkg, input_gpkgs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Loop through each input GeoPackage\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gpkg \u001b[38;5;129;01min\u001b[39;00m input_gpkgs:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     in_ds = \u001b[43mogr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpkg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_ds:\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to open \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\holmes\\micromamba_files\\envs\\semanticGIS\\Lib\\site-packages\\osgeo\\ogr.py:7258\u001b[39m, in \u001b[36mOpen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   7254\u001b[39m _WarnIfUserHasNotSpecifiedIfUsingExceptions()\n\u001b[32m   7255\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gdal\n\u001b[32m-> \u001b[39m\u001b[32m7258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ogr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: D:\\GeoILUN\\data\\Lemvig\\line_z.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def merge_geopackages(output_gpkg, input_gpkgs):\n",
    "    # Ensure the output GeoPackage does not already exist\n",
    "    driver = ogr.GetDriverByName('GPKG')\n",
    "    if os.path.exists(output_gpkg):\n",
    "        driver.DeleteDataSource(output_gpkg)\n",
    "    \n",
    "    out_ds = driver.CreateDataSource(output_gpkg)\n",
    "    \n",
    "    # Loop through each input GeoPackage\n",
    "    for gpkg in input_gpkgs:\n",
    "        in_ds = ogr.Open(gpkg)\n",
    "        if not in_ds:\n",
    "            print(f\"Failed to open {gpkg}\")\n",
    "            continue\n",
    "\n",
    "        # Copy each layer from the input GeoPackage to the output GeoPackage\n",
    "        for i in range(in_ds.GetLayerCount()):\n",
    "            in_layer = in_ds.GetLayerByIndex(i)\n",
    "            if out_ds.GetLayer(in_layer.GetName()):\n",
    "                print(f\"Layer {in_layer.GetName()} already exists in the output GeoPackage.\")\n",
    "                continue\n",
    "            # Copy layer to output GeoPackage, creating a new layer\n",
    "            out_layer = out_ds.CopyLayer(in_layer, in_layer.GetName())\n",
    "            if out_layer is None:\n",
    "                print(f\"Failed to copy layer {in_layer.GetName()} from {gpkg} to {output_gpkg}\")\n",
    "\n",
    "    out_ds = None  # Close the output data source to flush changes\n",
    "\n",
    "\n",
    "\n",
    "# Usage\n",
    "input_files = [lines_with_z, hs_with_z]\n",
    "output_file = burn_data\n",
    "merge_geopackages(output_file, input_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116752c2-0215-4f68-9957-62ab8224e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the original scripts\n",
    "script_path = src_root / 'cli' / 'burn_line_z.py'\n",
    "\n",
    "# Construct the command\n",
    "command = ['python', script_path, burn_data, v_rast, hydro_dtm]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6483775-38f9-4437-a4ed-1d5a5b962aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semanticGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
