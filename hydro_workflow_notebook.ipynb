{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb899c1",
   "metadata": {},
   "source": [
    "# DHM Hydro Adjustment Workflow\n",
    "\n",
    "This notebook demonstrates how to use the refactored `dhm-hydro-adjust` package to create hydrologically adjusted DTM rasters.\n",
    "\n",
    "The workflow includes:\n",
    "1. Filtering vector data by raster bounds\n",
    "2. Sampling elevation data for line and horseshoe objects\n",
    "3. Burning the adjustment objects into the DTM\n",
    "4. Creating a hydro-adjusted DTM output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3163087",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install the package in development mode:\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Or install dependencies directly:\n",
    "\n",
    "```bash\n",
    "pip install gdal numpy scipy tqdm geopandas shapely\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e61e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Import the hydro adjustment workflow\n",
    "from hydroadjust import HydroAdjustWorkflow, create_hydro_adjusted_dtm\n",
    "\n",
    "# Set up logging to see progress\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"DHM Hydro Adjust package imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f0abc",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define your input files and output directory here. Modify these paths according to your data location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION SECTION ===\n",
    "# Modify these paths according to your data location\n",
    "\n",
    "# Root directories\n",
    "dtm_root = Path('D:/GeoILUN/data/Lemvig')  # Directory containing DTM data\n",
    "correction_root = Path('D:/DK/tilpasninger')  # Directory containing correction vectors\n",
    "output_root = Path('./output')  # Output directory for results\n",
    "\n",
    "# Input files\n",
    "dtm_raster = dtm_root / 'dtm_10.tif'  # Input DTM raster\n",
    "horseshoe_file = correction_root / 'DHMHestesko.gpkg'  # Horseshoe vector data\n",
    "line_file = correction_root / 'DHMLinje.gpkg'  # Line vector data\n",
    "\n",
    "# Layer names in the vector files\n",
    "horseshoe_layer = 'dhmhestesko'\n",
    "line_layer = 'dhmlinje'\n",
    "\n",
    "# Optional: Maximum sampling distance for horseshoe profiles (in map units)\n",
    "# If None, will use half the diagonal pixel size of the input raster\n",
    "max_sample_distance = None  # e.g., 0.1 for 0.1 meter sampling\n",
    "\n",
    "print(f\"DTM Raster: {dtm_raster}\")\n",
    "print(f\"Horseshoe File: {horseshoe_file}\")\n",
    "print(f\"Line File: {line_file}\")\n",
    "print(f\"Output Directory: {output_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f689b2",
   "metadata": {},
   "source": [
    "## Method 1: Simple One-Step Workflow\n",
    "\n",
    "The easiest way to run the complete workflow in a single function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete workflow in one step\n",
    "try:\n",
    "    result_dtm = create_hydro_adjusted_dtm(\n",
    "        dtm_raster=dtm_raster,\n",
    "        horseshoe_file=horseshoe_file,\n",
    "        line_file=line_file,\n",
    "        output_dir=output_root,\n",
    "        horseshoe_layer=horseshoe_layer,\n",
    "        line_layer=line_layer,\n",
    "        max_sample_dist=max_sample_distance\n",
    "    )\n",
    "    \n",
    "    if result_dtm:\n",
    "        print(f\"\\n‚úÖ Success! Hydro-adjusted DTM created: {result_dtm}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No output created - no valid data found within raster bounds\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a6ef0",
   "metadata": {},
   "source": [
    "## Method 2: Step-by-Step Workflow\n",
    "\n",
    "For more control over the process, you can run each step individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the workflow\n",
    "workflow = HydroAdjustWorkflow(\n",
    "    dtm_raster=dtm_raster,\n",
    "    horseshoe_file=horseshoe_file,\n",
    "    line_file=line_file,\n",
    "    output_dir=output_root\n",
    ")\n",
    "\n",
    "print(\"Workflow initialized successfully!\")\n",
    "print(f\"Output files will be created in: {workflow.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get raster bounds and filter vector data\n",
    "print(\"Step 1: Filtering vector data by raster bounds...\")\n",
    "\n",
    "# Get the bounds of the DTM raster\n",
    "bounds = workflow.get_raster_bounds()\n",
    "print(f\"Raster bounds: {bounds}\")\n",
    "\n",
    "# Filter vector data to only include features within the raster bounds\n",
    "workflow.filter_vectors_by_bounds(\n",
    "    horseshoe_layer=horseshoe_layer,\n",
    "    line_layer=line_layer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector filtering complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd605fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Sample elevation for line objects\n",
    "print(\"Step 2: Sampling elevation for line objects...\")\n",
    "\n",
    "if os.path.exists(workflow.lines_filtered):\n",
    "    workflow.sample_line_z(\n",
    "        input_lines=workflow.lines_filtered,\n",
    "        output_lines=workflow.lines_with_z\n",
    "    )\n",
    "    print(\"‚úÖ Line elevation sampling complete\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No filtered line data found - skipping line sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sample elevation for horseshoe objects\n",
    "print(\"Step 3: Sampling elevation for horseshoe objects...\")\n",
    "\n",
    "if os.path.exists(workflow.hs_filtered):\n",
    "    workflow.sample_horseshoe_z_lines(\n",
    "        input_horseshoes=workflow.hs_filtered,\n",
    "        output_lines=workflow.hs_with_z,\n",
    "        max_sample_dist=max_sample_distance\n",
    "    )\n",
    "    print(\"‚úÖ Horseshoe elevation sampling complete\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No filtered horseshoe data found - skipping horseshoe sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Merge line files\n",
    "print(\"Step 4: Merging line files...\")\n",
    "\n",
    "input_files = []\n",
    "if os.path.exists(workflow.lines_with_z):\n",
    "    input_files.append(workflow.lines_with_z)\n",
    "if os.path.exists(workflow.hs_with_z):\n",
    "    input_files.append(workflow.hs_with_z)\n",
    "\n",
    "if input_files:\n",
    "    workflow.merge_line_files(\n",
    "        input_files=input_files,\n",
    "        output_file=workflow.combined_lines\n",
    "    )\n",
    "    print(f\"‚úÖ Merged {len(input_files)} files into {workflow.combined_lines}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No line files to merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d49de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Burn lines into DTM\n",
    "print(\"Step 5: Burning lines into DTM...\")\n",
    "\n",
    "if os.path.exists(workflow.combined_lines):\n",
    "    workflow.burn_lines_to_raster(\n",
    "        lines_file=workflow.combined_lines,\n",
    "        output_raster=workflow.hydro_dtm\n",
    "    )\n",
    "    print(f\"‚úÖ Hydro-adjusted DTM created: {workflow.hydro_dtm}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No combined lines file found - cannot burn into DTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb43280",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Let's check what files were created during the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f177f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of output files\n",
    "print(\"\\n=== WORKFLOW RESULTS ===\")\n",
    "print(f\"Output directory: {output_root}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "\n",
    "output_files = [\n",
    "    (\"Filtered horseshoes\", workflow.hs_filtered),\n",
    "    (\"Filtered lines\", workflow.lines_filtered),\n",
    "    (\"Horseshoes with Z\", workflow.hs_with_z),\n",
    "    (\"Lines with Z\", workflow.lines_with_z),\n",
    "    (\"Combined lines\", workflow.combined_lines),\n",
    "    (\"Hydro-adjusted DTM\", workflow.hydro_dtm)\n",
    "]\n",
    "\n",
    "for description, filepath in output_files:\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"‚úÖ {description}: {filepath} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {description}: {filepath} (not created)\")\n",
    "\n",
    "if os.path.exists(workflow.hydro_dtm):\n",
    "    print(f\"\\nüéâ SUCCESS: Final hydro-adjusted DTM ready at {workflow.hydro_dtm}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: No final DTM was created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe5034",
   "metadata": {},
   "source": [
    "## Alternative: Using Original CLI Scripts\n",
    "\n",
    "If you prefer to use the original command-line scripts from within the notebook, you can still do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach using the original CLI scripts\n",
    "import subprocess\n",
    "\n",
    "# Make sure the package is installed so the CLI commands are available\n",
    "try:\n",
    "    # Test if CLI commands are available\n",
    "    result = subprocess.run(['sample_line_z', '--help'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ CLI commands are available\")\n",
    "        \n",
    "        # Example usage of CLI commands\n",
    "        print(\"\\nExample CLI usage:\")\n",
    "        print(f\"sample_line_z {dtm_raster} {workflow.lines_filtered} {workflow.lines_with_z}\")\n",
    "        print(f\"sample_horseshoe_z_lines {dtm_raster} {workflow.hs_filtered} {workflow.hs_with_z}\")\n",
    "        print(f\"burn_line_z {workflow.combined_lines} {dtm_raster} {workflow.hydro_dtm}\")\n",
    "    else:\n",
    "        print(\"‚ùå CLI commands not available. Install the package with: pip install -e .\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå CLI commands not found. Install the package with: pip install -e .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376bd45",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Visualize Results**: Use your preferred GIS software to compare the original DTM with the hydro-adjusted DTM\n",
    "2. **Quality Control**: Check the adjustment objects and verify they were burned correctly\n",
    "3. **Integration**: Use the hydro-adjusted DTM in your hydrological modeling workflow\n",
    "\n",
    "The refactored workflow makes it easy to:\n",
    "- Run the complete process with sensible defaults\n",
    "- Customize individual steps as needed\n",
    "- Access intermediate results for quality control\n",
    "- Integrate with other notebook-based workflows"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
